{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###This documentation shows how to screen scrape the Hindawi APC' table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>First you will need to install Python. The easiest way to do so is to install <a href=\"http://docs.continuum.io/anaconda/install.html\">Anaconda</a></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/6Dv1wNvTPbg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0xb38cf20c>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo, HTML, Math, Image\n",
    "# how to install anaconda on mac\n",
    "YouTubeVideo('6Dv1wNvTPbg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Than you can copy every cells here or you can import this document in your anaconda folder (this part is not shown in the video I'll try to find an other video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Import all the necessary module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This module will help you retrieve the content within the Hindawi table\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Retrieving the hindawi html source page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hindawi_apc_url = 'http://www.hindawi.com/apc/'\n",
    "\n",
    "hindawi_html_page = urllib.urlopen(hindawi_apc_url) \n",
    "\n",
    "soup = BeautifulSoup(hindawi_html_page, 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=http://www.hindawi.com/apc/ width=900 height=550></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe src=http://www.hindawi.com/apc/ width=900 height=550></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This Hindawi page contains one HMTL table that we need to parse. Please look at the <a href='http://www.w3schools.com/html/html_tables.asp' >w3school documentation </a> about 'table' if your not familliar with HTML </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Selecting or Targeting what we want in the Hindawi's webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Within the Table all the 'tr' (table rows)\n",
    "content = soup.find_all('tr')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<tr class=\"subscription_table_head\">\n",
    "\t <th>Journal Title</th>\n",
    "\t <th>ISSN</th>\n",
    "\t <th class=\"last_th\">APC</th>\n",
    " </tr>, \n",
    " <tr class=\"subscription_table_plus\">\n",
    "\t <td>\n",
    "\t   <a href=\"/journals/aaa/\">Abstract and Applied Analysis</a>\n",
    "\t </td>\n",
    "\t <td>1687-0409</td>\n",
    "\t <td class=\"to_right\">$800</td>\n",
    " </tr>\n",
    " ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the first **tr** will contains the  table header (***Journal title, ISSN, APC***) we will start retrieving content after the first **tr**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table =[]\n",
    "\n",
    "#start with the second 'tr'\n",
    "for value in content[1:]:\n",
    "    #This will find all the td within this 'tr'\n",
    "    value = value.find_all('td')\n",
    "    \n",
    "    #index of VALUE: 0                ,     1,         2\n",
    "    #value ===> 'Abstract and Applied', '1687-0429', '$800'\n",
    "    \n",
    "    apc = value[2].text.strip()\n",
    "    #Let's remove the '$' sign if any\n",
    "    if \"$\" in apc:\n",
    "        apc = (apc.split('$'))[1]\n",
    "        apc = int(apc)\n",
    "    #if value == 'Free' than let's write 0 instead of Free\n",
    "    else:\n",
    "        apc = 0\n",
    "    table.append([value[0].text.strip(),value[1].text.strip(),apc] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-31ce5e4f6796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhindawi_apc_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Journal Title'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ISSN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'APC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "hindawi_apc_table = pd.DataFrame(a, columns=['Journal Title','ISSN','APC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Let's display the first 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hindawi_apc_table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Export the table to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export to Excel\n",
    "hindawi_apc_table.to_excel('Hindawi_apc_table.xlsx', sheet_name = 'Hindawi_APC_Table', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fa fa-file-excel-o fa-2x\" style=\"background-color:green;color:white\"></i>&nbsp;<a href=\"Hindawi_apc_table.xlsx\">Download the excel document (Hindawi_apc_table.xslx)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In resume to scrape the Table. You will need these steps:</p>\n",
    "<ol>\n",
    "  <li>Import all the necessary module: (<strong>BeautifulSoup</strong> and <strong>Pandas</strong>)</li>\n",
    "  <li>Retrieving the html page: <strong>soup = BeautifulSoup(hindawi_html_page, 'xml'</strong></li>\n",
    "  <li>Targeting the table</li>\n",
    "  <li>Within this table, you will need to loop through to retrieve what you are looking for</li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Références</h3>\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/\"> BeautifulSoup documentation</a></li>\n",
    "<li><a href=\"http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.to_excel.html\"> Pandas; DataFrame to Excel documentation</a></li>\n",
    "<li><a href=\"http://nbviewer.ipython.org/urls/bitbucket.org/hrojas/learn-pandas/raw/master/lessons/10%20-%20Lesson.ipynb\">Other Helpful NBViewer </a></li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
